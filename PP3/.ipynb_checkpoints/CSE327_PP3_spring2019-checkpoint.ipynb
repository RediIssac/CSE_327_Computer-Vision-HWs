{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CSE327 Programming Practice 3\n",
    "**Due date: 23:59 on May 16, 2019 (Thursday)**\n",
    "\n",
    "## Description\n",
    "---\n",
    "In this programming practice, we will examine the task of scene recognition starting with\n",
    "very simple methods: tiny images and nearest neighbor classification, and then\n",
    "move on to more advanced methods: bags of quantized local features and linear\n",
    "classifiers learned by support vector machines.\n",
    "\n",
    "Bag of words models are a popular technique for image classification inspired by\n",
    "models used in natural language processing. The model ignores or downplays word\n",
    "arrangement (spatial information in the image) and classifies based on a\n",
    "histogram of the frequency of visual words. The visual word \"vocabulary\" is\n",
    "established by clustering a large corpus of local features. See Szeliski chapter\n",
    "14.4.1 for more details on category recognition with quantized features. In\n",
    "addition, 14.3.2 discusses vocabulary creation and 14.1 covers classification\n",
    "techniques.\n",
    "\n",
    "For this PP you will be implementing a basic bag of words model. You will\n",
    "classify scenes into one of 15 categories by training and testing on the 15\n",
    "scene database (introduced in [Lazebnik et al.\n",
    "2006](http://www.di.ens.fr/willow/pdfs/cvpr06b.pdf), although built on top of\n",
    "previously published datasets).\n",
    "[Lazebnik et al. 2006](http://www.di.ens.fr/willow/pdfs/cvpr06b.pdf) is a great\n",
    "paper to read, although we will be implementing the baseline method the paper\n",
    "discusses (equivalent to the zero level pyramid) and not the more sophisticated\n",
    "spatial pyramid. For an excellent survey of\n",
    "pre-deep-learning feature encoding methods for bag of words models, see\n",
    "[Chatfield et al, 2011](http://www.robots.ox.ac.uk/~vgg/research/encoding_eval/).\n",
    "\n",
    "You are required to implement 2 different image representations: tiny images and bags of SIFT features, and 2 different classification techniques: nearest neighbor and linear SVM. There are 3 problems plus a performance report in this PP with a total of 100 points. 1 bonus question with extra 10 points is provided under problem 3. The maximum points you may earn from this homework is 100 + 10 = 110 points. Be sure to read **Submission Guidelines** below. They are important.\n",
    "\n",
    "## Dataset\n",
    "---\n",
    "The starter code trains and tests on 100 images from each category (i.e. 1500\n",
    "training examples total and 1500 test cases total). In a real research paper,\n",
    "one would be expected to test performance on random splits of the data into\n",
    "training and test sets, but the starter code does not do this to ease debugging.\n",
    "\n",
    "Under your downloaded folder, there should be a folder named \"data\" (i.e. XXX/Surname_Givenname_SBUID/data) containing the images.\n",
    "**Delete** the data subfolder before submission or the Google Classroom won't let you do so because\n",
    "of the size. There should be only one .ipynb file under your root folder Surname_Givenname_SBUID.\n",
    "## Starter Code\n",
    "---\n",
    "To make your task a little easier, below we provide some starter code which\n",
    "randomly guesses the category of every test image and achieves about 6.6% accuracy\n",
    "(1 out of 15 guesses is correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import packages here\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "The accuracy of my dummy model is 6.60%\n"
     ]
    }
   ],
   "source": [
    "class_names = [name[11:] for name in glob.glob('data/train/*')]\n",
    "class_names = dict(zip(xrange(len(class_names)), class_names))\n",
    "\n",
    "def load_dataset(path, num_per_class=-1):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for id, class_name in class_names.iteritems():\n",
    "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
    "        if num_per_class > 0:\n",
    "            img_path_class = img_path_class[:num_per_class]\n",
    "        labels.extend([id]*len(img_path_class))\n",
    "        for filename in img_path_class:\n",
    "            data.append(cv2.imread(filename, 0))\n",
    "    return data, labels\n",
    "\n",
    "# load training dataset\n",
    "train_data, train_label = load_dataset('data/train/')\n",
    "#print(train_data[0], train_label[0], \"train data and label\")\n",
    "train_num = len(train_label)\n",
    "print(train_num)\n",
    "# load testing dataset\n",
    "test_data, test_label = load_dataset('data/test/', 100)\n",
    "#print(test_data[0], test_label[0], \" test data and label\")\n",
    "test_num = len(test_label)\n",
    "print(test_num)\n",
    "# feature extraction\n",
    "def extract_feat(raw_data):\n",
    "    feat_dim = 1000\n",
    "    feat = np.zeros((len(raw_data), feat_dim), dtype=np.float32)\n",
    "    for i in xrange(feat.shape[0]):\n",
    "        feat[i] = np.reshape(raw_data[i], (raw_data[i].size))[:feat_dim] # dummy implemtation\n",
    "        \n",
    "    return feat\n",
    "\n",
    "train_feat = extract_feat(train_data)\n",
    "#print(train_feat[0], \"train feat\")\n",
    "test_feat = extract_feat(test_data)\n",
    "\n",
    "#print(test_feat[0], \"test feat\")\n",
    "\n",
    "# model training: take feature and label, return model\n",
    "def train(X, Y):\n",
    "    return 0 # dummy implementation\n",
    "\n",
    "# prediction: take feature and model, return label\n",
    "def predict(model, x):\n",
    "    return np.random.randint(15) # dummy implementation\n",
    "\n",
    "# evaluation\n",
    "predictions = [-1]*len(test_feat)\n",
    "for i in xrange(test_num):\n",
    "    predictions[i] = predict(None, test_feat[i])\n",
    "    \n",
    "accuracy = sum(np.array(predictions) == test_label) / float(test_num)\n",
    "\n",
    "print \"The accuracy of my dummy model is {:.2f}%\".format(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Problem 1: Tiny Image Representation + Nearest Neighbor Classifier\n",
    "{25 points} You will start by implementing the tiny image representation and the nearest neighbor classifier. They are easy to understand, easy to implement, and run very quickly for our experimental setup.\n",
    "\n",
    "The \"tiny image\" feature is one of the simplest possible image representations. One simply resizes each image to a small, fixed resolution. You are required to **resize the image to 16x16**. It works slightly better if the tiny image is made to have zero mean and unit length (normalization). This is not a particularly good representation, because it discards all of the high frequency image content and is not especially invariant to spatial or brightness shifts. We are using tiny images simply as a baseline.\n",
    "\n",
    "The nearest neighbor classifier is equally simple to understand. When tasked with classifying a test feature into a particular category, one simply finds the \"nearest\" training example (L2 distance is a sufficient metric) and assigns the label of that nearest training example to the test example. The nearest neighbor classifier has many desirable features — it requires no training, it can learn arbitrarily complex decision boundaries, and it trivially supports multiclass problems. It is quite vulnerable to training noise, though, which can be alleviated by voting based on the K nearest neighbors (but you are not required to do so). Nearest neighbor classifiers also suffer as the feature dimensionality increases, because the classifier has no mechanism to learn which dimensions are irrelevant for the decision.\n",
    "\n",
    "Report your classification accuracy on the test sets and time consumption.\n",
    "\n",
    "**Hints**:\n",
    "- Use [cv2.resize()](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#resize) to resize the images;\n",
    "- Use [NearestNeighbors in Sklearn](http://scikit-learn.org/stable/modules/neighbors.html) as your nearest neighbor classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Write your codes here\n",
    "# resize the image 16 x16\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import urllib\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "\n",
    "\n",
    "# pred1, label1 = # train_and_test(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Set: 1500\n",
      "Test set: 1500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Algorithm for implementing KNN\n",
    "# First: Handle DATA\n",
    "    # Open the dataset and split into test and train dataset\n",
    "class_names = [name[11:] for name in glob.glob('data/train/*')]\n",
    "class_names = dict(zip(xrange(len(class_names)), class_names))\n",
    "\n",
    "def load_dataset(path, num_per_class = -1):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for id, class_name in class_names.iteritems():\n",
    "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
    "        if num_per_class > 0:\n",
    "            img_path_class = img_path_class[:num_per_class]\n",
    "        labels.extend([id]*len(img_path_class))\n",
    "        for filename in img_path_class:\n",
    "            data.append(cv2.imread(filename, 0))\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# loading the data\n",
    "trainingSet, train_label = load_dataset('data/train/')\n",
    "\n",
    "train_num = len(train_label)\n",
    "testSet, test_label = load_dataset('data/test/', 100)\n",
    "test_num = len(test_label)\n",
    "\n",
    "# print(\"train Set: \" + repr(len(trainingSet)))\n",
    "# print(\"Test set: \"+ repr(len(testSet)))\n",
    "\n",
    "# plt.figure(figsize=(18,8))\n",
    "# for i in range(0,10):\n",
    "#     plt.subplot(5,45,i+1)\n",
    "#     plt.imshow(trainingSet[i], 'gray')\n",
    "#     s = str(train_label[i])\n",
    "#     plt.title(s)\n",
    "#     plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_feat(raw_data): \n",
    "    features = []\n",
    "    for img in raw_data:\n",
    "        resize_img = cv2.resize(img, (16,16), interpolation=cv2.INTER_CUBIC)\n",
    "        np_img=np.array(resize_img)\n",
    "        mean_image=np.mean(np_img)\n",
    "        var_image=np.var(img,ddof=1)\n",
    "        normalized_one=np_img-mean_image\n",
    "        final_image=np.divide(normalized_one,var_image)\n",
    "        final_image = final_image.ravel()  # flatten the image\n",
    "        features.append(final_image)\n",
    "    np_features = np.array(features)\n",
    "    return np_features\n",
    "\n",
    "train_feat = extract_feat(trainingSet)\n",
    "train_labels_np = np.array(train_label)\n",
    "train_labels_np_t = transpose(train_labels_np)\n",
    "\n",
    "test_feat = extract_feat(testSet)\n",
    "test_labels_np = np.array(test_label)\n",
    "test_labels_np_t = transpose(test_labels_np)\n",
    "\n",
    "\n",
    "n_neighbors = 15\n",
    "    \n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "clf.fit(train_feat, train_labels_np_t) \n",
    "predictions = clf.predict(test_feat)\n",
    "accuracy = sum(predictions == test_labels_np) / float(test_num)\n",
    "print \"The accuracy of my model is {:.2f}%\".format(accuracy*100) \n",
    "\n",
    "# def flatten (train_data):\n",
    "#     flattend_train_data=[]\n",
    "#     for feat in train_data:\n",
    "#         flat_feat=feat.ravel()\n",
    "#         flattend_train_data.append(flat_feat)\n",
    "#     np_flattend = np.array(flattend_train_data)\n",
    "#     return np_flattend\n",
    "\n",
    "\n",
    "#     feat_dim = 256\n",
    "#     feat = np.zeros((len(raw_data), feat_dim), dtype=np.float32)\n",
    "#     print(raw_data[0].shape)\n",
    "    \n",
    "#     for i in xrange(feat.shape[0]):\n",
    "#         # resize image to 16x16\n",
    "#         resized_image = cv2.resize(raw_data[i], None, fx = (16/float(raw_data[i].shape[1])), fy = (16/float(raw_data[i].shape[0])))\n",
    "#         # flatten image\n",
    "#         resized_image = resized_image.flatten()\n",
    "#         feat[i] = normalize(resized_image.flatten())[:feat_dim]\n",
    "\n",
    "#     return feat    \n",
    "   \n",
    "# def normalize(tinyImage):\n",
    "#     sumN = 0.0\n",
    "#     normalizedImage = []\n",
    "#     for i in range(len(tinyImage)):\n",
    "#         sumN += tinyImage[i]\n",
    "#     for image in tinyImage:\n",
    "#         normalizedImage.append(image/sumN) \n",
    "#     return normalizedImage\n",
    "        \n",
    "# def extract_feat(raw_data):\n",
    "#     feat_dim = (len(raw_data))\n",
    "#     feat = []\n",
    "#     size = 16*16\n",
    "#     for i in xrange(0,feat_dim):\n",
    "#         feat.append(cv2.resize(raw_data[i],(16,16)))\n",
    "#         feat[i] = (feat[i]+0.0)/255 #normalizing\n",
    "#         #mean = np.mean(feat[i])\n",
    "#         #feat[i] = feat[i] - mean \n",
    "#         feat[i] = np.array(feat[i]).reshape(size)\n",
    "#     return feat\n",
    "\n",
    "# # extracting features\n",
    "\n",
    "#  flatten a data given a 2d array\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of my model is 20.53%\n"
     ]
    }
   ],
   "source": [
    "class_names = [name[11:] for name in glob.glob('data/train/*')] \n",
    "class_names = dict(zip(xrange(len(class_names)), class_names))\n",
    "\n",
    "def load_dataset(path, num_per_class=-1):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for id, class_name in class_names.iteritems():\n",
    "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
    "        if num_per_class > 0:\n",
    "            img_path_class = img_path_class[:num_per_class]  \n",
    "            labels.extend([id]*len(img_path_class)) \n",
    "        for filename in img_path_class:\n",
    "            img=cv2.imread(filename,0)\n",
    "            resize_img = cv2.resize(img, (16,16), interpolation=cv2.INTER_CUBIC)\n",
    "            np_img=np.array(resize_img)\n",
    "            mean_image=np.mean(np_img)\n",
    "            var_image=np.var(img,ddof=1)\n",
    "            normalized_one=np_img-mean_image\n",
    "            final_image=np.divide(normalized_one,var_image)\n",
    "            data.append(final_image)   \n",
    "    return data, labels\n",
    "\n",
    "def flat_input (train_data):\n",
    "    flat_train_data=[]\n",
    "    for element in train_data:\n",
    "        flat_element=element.ravel()\n",
    "        flat_train_data.append(flat_element)\n",
    "    X=np.array(flat_train_data)\n",
    "    return X\n",
    "\n",
    "def knearst_neighbor_report():\n",
    "    train_data, train_label = load_dataset('data/train/', 100)\n",
    "    train_num = len(train_label) \n",
    "    test_data, test_label = load_dataset('data/test/', 100)\n",
    "    test_num = len(test_label) \n",
    "    X=flat_input(train_data)\n",
    "    train_labels_np=np.array(train_label)\n",
    "    y=np.transpose(train_labels_np)\n",
    "\n",
    "    test_X=flat_input(test_data)\n",
    "    test_labels_np=np.array(test_label)\n",
    "    test_y=np.transpose(test_labels_np)\n",
    "    \n",
    "    n_neighbors = 15\n",
    "    \n",
    "    \n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "    clf.fit(X, y) \n",
    "    Z = clf.predict(test_X)\n",
    "    accuracy = sum(Z == test_labels_np) / float(test_num)\n",
    "    print \"The accuracy of my model is {:.2f}%\".format(accuracy*100)   \n",
    "knearst_neighbor_report()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(train_feat)\n",
    "# distances, indices = nbrs.kneighbors(test_feat)\n",
    "# predictions = np.array(indices).reshape(len(test_label))/100\n",
    "\n",
    "# clf = neighbors.KNeighborsClassifier(n_neighbors=6)\n",
    "# # #clf = NearestNeighbors(n_neighbors=6)\n",
    "# # # Training\n",
    "\n",
    "# # train_feat = np.array(train_feat)\n",
    "# # # for i in xrange(train_num):\n",
    "# clf.fit(train_feat, train_label)\n",
    "# # # nbrs = NearestNeighbors(n_neighbors=6) \n",
    "# # # nbrs.fit(train_feat)\n",
    "\n",
    "# # # evaluation\n",
    "# # # \n",
    "# # # test = nbrs.NearestNeighbors(test_feat)\n",
    "# predictions =[]\n",
    "# predictions = [-1]*len(test_feat)\n",
    "# for i in xrange(test_num):\n",
    "#     predictions[i] = clf.predict([test_feat[i]])[0]\n",
    "# print(predictions[0], 'predictions')  \n",
    "\n",
    "\n",
    "# # for i in range(test_num):\n",
    "# #     print('>predicted=' + repr(predictions[i])+ ', actual=' + repr(test_label[i]))\n",
    "   \n",
    "# # accuracy = sum(np.array(predictions) == test_label) / float(test_num)\n",
    "\n",
    "# # print \"The accuracy of my model is {:.2f}%\".format(accuracy*100)    \n",
    "    \n",
    "    \n",
    "\n",
    "# def get_accuracy(actual_label, predicted_label):\n",
    "#     correct = 0\n",
    "#     for i in xrange(test_num):\n",
    "#         if predicted_label[i] == actual_label[i]:\n",
    "#             correct += 1\n",
    "        \n",
    "#     accuracy =correct*100 / float(test_num)\n",
    "#     return accuracy\n",
    "# get_accuracy(test_label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: summarizing the accuracy of predicitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Problem 2: Bag of SIFT Representation + Nearest Neighbor Classifer\n",
    "{35 points}\n",
    "After you have implemented a baseline scene recognition pipeline it is time to\n",
    "move on to a more sophisticated image representation — bags of quantized SIFT\n",
    "features. Before we can represent our training and testing images as bag of\n",
    "feature histograms, we first need to establish a vocabulary of visual words. We\n",
    "will form this vocabulary by sampling many local features from our training set\n",
    "(10's or 100's of thousands) and then cluster them with k-means. The number of\n",
    "k-means clusters is the size of our vocabulary and the size of our features. For\n",
    "example, you might start by clustering many SIFT descriptors into k=50 clusters.\n",
    "This partitions the continuous, 128 dimensional SIFT feature space into 50\n",
    "regions. For any new SIFT feature we observe, we can figure out which region it\n",
    "belongs to as long as we save the centroids of our original clusters. Those\n",
    "centroids are our visual word vocabulary. Because it can be slow to sample and\n",
    "cluster many local features, the starter code saves the cluster centroids and\n",
    "avoids recomputing them on future runs.\n",
    "\n",
    "Now we are ready to represent our training and testing images as histograms of\n",
    "visual words. For each image we will densely sample many SIFT descriptors.\n",
    "Instead of storing hundreds of SIFT descriptors, we simply count how many SIFT\n",
    "descriptors fall into each cluster in our visual word vocabulary. This is done\n",
    "by finding the nearest neighbor k-means centroid for every SIFT feature. Thus,\n",
    "if we have a vocabulary of 50 visual words, and we detect 220 distinct SIFT\n",
    "features in an image, our bag of SIFT representation will be a histogram of 50\n",
    "dimensions where each bin counts how many times a SIFT descriptor was assigned\n",
    "to that cluster. The total of all the bin-counts is 220. The histogram should be\n",
    "normalized so that image size does not dramatically change the bag of features\n",
    "magnitude.\n",
    "\n",
    "**Note**: \n",
    "- Instead of using SIFT to detect invariant keypoints which is time-consuming,\n",
    "  you are recommended to densely sample keypoints in a grid with certain step\n",
    "  size (sampling density) and scale.\n",
    "- There are many design decisions and free parameters for the bag of SIFT\n",
    "  representation (number of clusters, sampling density, sampling scales, SIFT\n",
    "  parameters, etc.) so accuracy might vary from 50% to 60%.\n",
    "- Indicate clearly the parameters you use along with the prediction accuracy\n",
    "  on test set and time consumption.\n",
    "\n",
    "**Hints**:\n",
    "- Use [KMeans in Sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "  to do clustering and find the nearest cluster centroid for each SIFT feature;\n",
    "- Use `cv2.xfeatures2d.SIFT_create()` to create a SIFT object;\n",
    "- Use `sift.compute()` to compute SIFT descriptors given densely sampled keypoints\n",
    "  ([cv2.Keypoint](https://docs.opencv.org/3.0-beta/modules/core/doc/basic_structures.html?highlight=keypoint#keypoint))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-626-545310db059a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# k-Nearest neighbor model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[0mBoW_neigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'distance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, algorithm='kd_tree', leaf_size=40\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mBoW_neigh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your codes here\n",
    "#from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import *\n",
    "\n",
    "# initialize SIFT detector\n",
    "sift = cv2.SIFT()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "train_descriptors = []\n",
    "for img in train_data:\n",
    "    kp1, des1 = sift.detectAndCompute(img, None)\n",
    "    train_descriptors.append((kp1,des1))\n",
    "\n",
    "train_des_list = train_descriptors[0][1]\n",
    "for kp, des in train_descriptors[1:]:\n",
    "    train_des_list = np.vstack((train_des_list, des))\n",
    "\n",
    "#Performing kmeans clustering\n",
    "vocab, variance = kmeans(train_des_list, 100, 1) \n",
    "\n",
    "train_feat = np.zeros((train_num, 100), \"float32\")\n",
    "for i in xrange(train_num):\n",
    "    words, distance = vq(train_descriptors[i][1],vocab)\n",
    "    for w in words:\n",
    "        train_feat[i][w] += 1\n",
    "\n",
    "\n",
    "#Test data\n",
    "\n",
    "test_descriptors = []\n",
    "for img in test_data:\n",
    "    kp2, des2 = sift.detectAndCompute(img, None)\n",
    "    test_descriptors.append((kp2, des2))\n",
    "    \n",
    "test_des_list = test_descriptors[0][1]\n",
    "for kp, des in test_descriptors[0:]:\n",
    "    test_des_list = np.vstack((test_des_list, des))\n",
    "    \n",
    "test_features = np.zeros((test_num, 100), \"float32\")\n",
    "for i in xrange(test_num):\n",
    "    words, distance = vq(test_descriptors[i][1],vocab)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "# k-Nearest neighbor model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of BoW with nearest neighbor model is 45.73%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BoW_neigh = KNeighborsClassifier(n_neighbors=20, weights='distance', p=2) #, algorithm='kd_tree', leaf_size=40\n",
    "BoW_neigh.fit(train_feat, train_label)\n",
    "\n",
    "\n",
    "test_pred2 = BoW_neigh.predict(test_features)\n",
    "\n",
    "accuracy = np.sum(test_pred2 == test_label) / float(test_num)\n",
    "print \"The accuracy of BoW with nearest neighbor model is {:.2f}%\".format(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500L, 250L) desc set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "obs and code should have same number of features (columns)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-636-712a42956a2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mtrain_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_descriptors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mtrain_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\asus\\Anaconda2\\CSE327\\lib\\site-packages\\scipy\\cluster\\vq.pyc\u001b[0m in \u001b[0;36mvq\u001b[1;34m(obs, code_book, check_finite)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_code_book\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpy_vq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode_book\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_vq.pyx\u001b[0m in \u001b[0;36mscipy.cluster._vq.vq\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: obs and code should have same number of features (columns)"
     ]
    }
   ],
   "source": [
    "# Write your codes here\n",
    "# find interesting keypoints - > \n",
    "# question normally we find sift descriptors from the image it self right do we need to resize the image now\n",
    "# answer :- resizing would be fine and use the whole image when finiding the descirptor\n",
    "from sklearn.cluster import KMeans\n",
    "sift = cv2.SIFT()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "# sift descriptors are found for keypoints\n",
    "# first: find key points using cv2.keypoints and find the descriptors\n",
    "def computeDescriptors(dataSet):\n",
    "    dimention = 250\n",
    "    keyPointsSet = []\n",
    "    descriptorsSet = []\n",
    "    data_descriptors = []\n",
    "    # calcualte the key points and descirptors\n",
    "    for image in dataSet:\n",
    "        kp, des = sift.detectAndCompute(image, None)\n",
    "        keyPointsSet.append(kp)\n",
    "        descriptorsSet.append(des)\n",
    "        data_descriptors.append((kp,des))\n",
    "    #  change each image into one d array flatten it then change it to\n",
    "    # a list to construct a 2d np array\n",
    "    #  2d np array image -> 1d flat list -> all images gives 2d list -> to 2d np arrays\n",
    "    \n",
    "    tobePassed = [] \n",
    "    for des in descriptorsSet:\n",
    "        tobePassed.append(des.flatten()[:dimention].tolist())\n",
    "    descSet = np.array(tobePassed)\n",
    "    print descSet.shape, \"desc set\"\n",
    "    # notice this only returns the arranged np array of descriptors if u need keypoints u can also \n",
    "    # return it in the future\n",
    "    return descSet, data_descriptors\n",
    "\n",
    "\n",
    "\n",
    "# calculate the k means cluster\n",
    "train_siftDesc, train_descriptors = computeDescriptors(trainingSet)\n",
    "\n",
    "\n",
    "# find cluster using k means\n",
    "vocab, variance = kmeans(train_siftDesc, 100, 1) \n",
    "\n",
    "train_feat = np.zeros((train_num, 100), \"float32\")\n",
    "for i in xrange(train_num):\n",
    "    words, distance = vq(train_descriptors[i][1],vocab)\n",
    "    for w in words:\n",
    "        train_feat[i][w] += 1\n",
    "\n",
    "\n",
    "#Test data\n",
    "\n",
    "test_siftDesc, test_descriptors = computeDescriptors(testSet)\n",
    "test_features = np.zeros((test_num, 100), \"float32\")\n",
    "for i in xrange(test_num):\n",
    "    words, distance = vq(test_descriptors[i][1],vocab)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "        \n",
    "BoW_neigh = KNeighborsClassifier(n_neighbors=2, weights='distance', p=2) #, algorithm='kd_tree', leaf_size=40\n",
    "BoW_neigh.fit(train_feat, train_label)\n",
    "\n",
    "\n",
    "test_pred2 = BoW_neigh.predict(test_features)\n",
    "\n",
    "accuracy = np.sum(test_pred2 == test_label) / float(test_num)\n",
    "print \"The accuracy of BoW with nearest neighbor model is {:.2f}%\".format(accuracy*100)\n",
    "\n",
    "\n",
    "\n",
    "# predictions_Kmeans = []\n",
    "# sump = 0.0\n",
    "# counter = 0\n",
    "# correct_count = 0\n",
    "# for test in test_siftDesc:\n",
    "    \n",
    "#     predict = kmeans.predict([test])\n",
    "#     print(predict)\n",
    "#     print(predict, \"predicting ->  actual: \", test_label[counter])\n",
    "#     if (predict == test_label[counter]):\n",
    "#         correct_count += 1\n",
    "#     predictions_Kmeans.append(predict)\n",
    "#     counter += 1\n",
    " \n",
    "# for i in predictitons:\n",
    "# # use the predictions for \n",
    "# clf_2 = neighbors.KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# clf_2.fit(predictions_Kmeans, test_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# acc = correct_count/float(10)\n",
    "# print(acc*100, \"% : acc\")\n",
    "# accuracy_K = sum(np.array(predictions_Kmeans) == test_label) / float(test_num)\n",
    "\n",
    "# print \"The accuracy of my model is \", accuracy_K*100, \"%\"  \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# question: after getting the kmeans which is a 1 d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(descriptorsSet, \"descr SEt\") \n",
    "# #listdes = descriptorsSet.tolist()\n",
    "# print(descriptorsSet[:2], \"descriptors\")\n",
    "# N = listdes[0].flatten()\n",
    "# G = listdes[1].flatten()\n",
    "# print(N, \"flattend\")\n",
    "\n",
    "# X = descriptorsSet[0].reshape(-1,1)\n",
    "# Y = descriptorsSet[1].reshape(-1,1)\n",
    "# print(X, \"reshaped array\")\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(np.array([N,G]))   \n",
    "    \n",
    "# print(kmeans.labels_) \n",
    "# kmeans.predict(Y)\n",
    "# fiind the SIFT descriptors and there histograms\n",
    "# find one centroid by clustering all the siFT descriptors of one image into one cluster using k means\n",
    "# the center or the mean of the clusters become the vocabulary of that specific histogram.\n",
    "# whenever a new image comes itwill be converted to a cluster and we will check what percent it is a man a car or things like that\n",
    "# performace is about 50-60 % if we use those bag of words and then do KNN to classify them rather than svm\n",
    "# SVM performs the best waty of classifying the image\n",
    "\n",
    "#pred2, label2 = # train_and_test(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Problem 3: Bag of SIFT Representation + one-vs-all SVMs\n",
    "{20 points}\n",
    "The last task is to train one-vs-all linear SVMS to operate in the bag of SIFT\n",
    "feature space. Linear classifiers are one of the simplest possible learning\n",
    "models. The feature space is partitioned by a learned hyperplane and test cases\n",
    "are categorized based on which side of that hyperplane they fall on. Despite\n",
    "this model being far less expressive than the nearest neighbor classifier, it\n",
    "will often perform better.\n",
    "\n",
    "You do not have to implement the support vector machine. However, linear\n",
    "classifiers are inherently binary and we have a 15-way classification problem\n",
    "(the library has handled it for you). To decide which of 15 categories a test\n",
    "case belongs to, you will train 15 binary, one-vs-all SVMs. One-vs-all means\n",
    "that each classifier will be trained to recognize 'forest' vs 'non-forest',\n",
    "'kitchen' vs 'non-kitchen', etc. All 15 classifiers will be evaluated on each\n",
    "test case and the classifier which is most confidently positive \"wins\". E.g. if\n",
    "the 'kitchen' classifier returns a score of -0.2 (where 0 is on the decision\n",
    "boundary), and the 'forest' classifier returns a score of -0.3, and all of the\n",
    "other classifiers are even more negative, the test case would be classified as a\n",
    "kitchen even though none of the classifiers put the test case on the positive\n",
    "side of the decision boundary. When learning an SVM, you have a free parameter\n",
    "$\\lambda$ (lambda) which controls how strongly regularized the model is. Your\n",
    "accuracy will be very sensitive to $\\lambda$, so be sure to try many values.\n",
    "\n",
    "Indicate clearly the parameters you use along with the prediction accuracy on\n",
    "test set and time consumption.\n",
    "\n",
    "**Bonus {10 points}**: 10 points will be given to students whose accuracy\n",
    "  ranks top 3 in this homework. Don't cheat and don't train your model on\n",
    "  testing data, a separate testing dataset will be used to evaluate your model.\n",
    "\n",
    "**Hints**:\n",
    "- Use SVM in\n",
    "  [Sklearn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm)\n",
    "  (recommended) or\n",
    "  [OpenCV](https://docs.opencv.org/3.0-alpha/modules/ml/doc/support_vector_machines.html)\n",
    "  to do training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-632-901e6245126d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_feat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Write your codes here\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma = 0.2, C = 15)\n",
    "\n",
    "X = train_feat\n",
    "print(train_feat.shape)\n",
    "y = train_label\n",
    "\n",
    "clf.fit(X, y)  \n",
    "\n",
    "correct_count = 0\n",
    "prediction = []\n",
    "for index in range (0, len(test_features)):\n",
    "    predict = clf.predict([test_features[index]])\n",
    "    if predict == test_label[index]:\n",
    "        correct_count += 1\n",
    "    prediction.append(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Performance Report\n",
    "---\n",
    "{20 points}\n",
    "Please report the performance of the following combinations **in the given order**\n",
    "in terms of the time consumed and classification accuracy. Describe your algorithm,\n",
    "any decisions you made to write your algorithm in your particular way, and how\n",
    "different choices you made affect it. Compute and draw a (normalized) [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix), and discuss\n",
    "where the method performs best and worse for each of the combination.\n",
    "Here is an [example](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py) of how to compute confusion matrix.\n",
    "\n",
    "\n",
    "1st: Tiny images representation and nearest neighbor classifier (accuracy of about 18-25%).<br>\n",
    "2nd: Bag of SIFT representation and nearest neighbor - classifier (accuracy of about 50-60%). <br>\n",
    "3rd: Bag of SIFT representation and linear SVM classifier (accuracy of about 60-70%). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First combination:** <br>\n",
    "\n",
    "-- Time consumed and prediction accuracy\n",
    "\n",
    "-- Algorithm descriptions and discussions\n",
    "\n",
    "-- Confusion matrix observations\n",
    "\n",
    "**Second combination:** <br>\n",
    "\n",
    "-- Time consumed and prediction accuracy\n",
    "\n",
    "-- Algorithm descriptions and discussions\n",
    "\n",
    "-- Confusion matrix observations\n",
    "\n",
    "**Third combination:** <br>\n",
    "\n",
    "-- Time consumed and prediction accuracy\n",
    "\n",
    "-- Algorithm descriptions and discussions\n",
    "\n",
    "-- Confusion matrix observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "c_names = [name[11:] for name in glob.glob('data/train/*')]\n",
    "\n",
    "#First combination:\n",
    "# Confusion matrix\n",
    "cm1 = confusion_matrix(pred1, label1)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cm1, c_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "#Second combination:\n",
    "# Confusion matrix\n",
    "cm2 = confusion_matrix(pred2, label2)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cm2, c_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "#Third combination:\n",
    "# Confusion matrix\n",
    "cm3 = confusion_matrix(pred3, label3)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cm3, c_names, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines\n",
    "---\n",
    "Extract the downloaded .zip file to a folder of your preference. The input and output paths are predefined and **DO NOT** change them. The image read and write functions are already written for you. \n",
    "\n",
    "When submitting your .zip file through blackboard, please <br> \n",
    "-- name your .zip file as Surname_Givenname_SBUID (example: Trump_Donald_11113456). <br>\n",
    "-- DO NOT change the folder structre, please just fill in the blanks. <br>\n",
    "\n",
    "You are encouraged to make posts and answer questions on Google Classroom. Due to the amount of emails I receive from past years, it is unfortunate that I won't be able to reply all your emails. Please ask questions on Google Classroom and send emails only when it is private.\n",
    "\n",
    "If you alter the folder strucutres, the grading of your PP will be significantly delayed and possibly penalized. And I **WILL NOT** reply to any email regarding this matter.\n",
    "\n",
    "Be aware that your codes will undergo plagiarism checker both vertically and horizontally. Please do your own work.\n",
    "\n",
    "Late submission penalty: <br>\n",
    "There will be a 10% penalty per day for late submission. However, you will have 3 days throughout the whole semester to submit late without penalty. Note that the grace period is calculated by days instead of hours. If you submit the homework one minute after the deadline, one late day will be counted. Likewise, if you submit one minute after the deadline, the 10% penaly will be imposed if not using the grace period. All late penalties incurred will be applied to your scores at the end of the semester.\n",
    "\n",
    "Some important things to note: <br>\n",
    "A correct pipeline for your submitted folder structure: <br>\n",
    "1) Download the .zip file from Google Classroom and unzip it (e.g. CSE327-PP3-Spring19.zip) <br>\n",
    "2) The unzipped folder should have name like CSE327-PP3-Spring19, rename it to Surname_Givenname_SBUID <br>\n",
    "3) Write your codes in the given .ipynb file <br>\n",
    "4) Save the visual outputs in the .ipynb file <br>\n",
    "5) Rezip your Surname_Givenname_SBUID folder and submit <br>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "HW3.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
