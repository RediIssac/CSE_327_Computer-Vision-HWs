{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret = True W = 1280 H = 720 channel = 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-b9b6d34caf5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;31m# should be called once the card is detected and the hand is moving back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mtrack_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Save the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-b9b6d34caf5c>\u001b[0m in \u001b[0;36mtrack_frame\u001b[1;34m(size_back)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#dist = sqrt(pow((x2-x1),2) + pow((y2-y1),2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#for c in centroids[:size_back]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('south.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "print('ret =', ret, 'W =', frame.shape[1], 'H =', frame.shape[0], 'channel =', frame.shape[2])\n",
    "\n",
    "\n",
    "FPS= 20.0\n",
    "FrameSize=(frame.shape[1], frame.shape[0])\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "out = cv2.VideoWriter('Video_output.avi', fourcc, FPS, FrameSize, 0)\n",
    "\n",
    "\n",
    "# initalizing an array for saving centroids\n",
    "big_data = []\n",
    "centroids = []\n",
    "\n",
    "def track_frame(size_back):\n",
    "   \n",
    "    #dist = sqrt(pow((x2-x1),2) + pow((y2-y1),2))\n",
    "    \n",
    "    \n",
    "    print(len(centroids)-len(size_back))\n",
    "    \n",
    "    # we need to iterate starting from the last frame back till the size given\n",
    "    back = len(centroids)-len(size_back)\n",
    "    #for i in range(back, len(centroids)):\n",
    "   \n",
    "    for c in centroids[:size_back]:\n",
    "         # put text and highlight the center\n",
    "    \n",
    "        cv2.circle(frame, (centroids[i][0], centroids[i][1]), 5, (255, 255, 255), -1)\n",
    "    \n",
    "        cv2.putText(frame, \"c\", (centroids[i][0] - 25, centroids[i][1] - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    print(\"hey\",centroids[0][0])\n",
    "    #print(centroids[1])\n",
    "    \n",
    "    # I was trying to calculate the slope here\n",
    "    x2 = centroids[len(centroids)-1][0]\n",
    "    y2 = centroids[len(centroids)-1][1]\n",
    "    x1 = centroids[back][0]\n",
    "    y1 = centroids[back][1]\n",
    "    \n",
    "    \n",
    "    c_y = y2-y1\n",
    "    c_x = x2 - x1\n",
    "    slope = (y2-y1)/(x2-x1)\n",
    "    # base on the sign of the slope predicte where the direction would be\n",
    "    if (slope >= 0):\n",
    "        if(c_y >=0 & c_x >=0):\n",
    "            print(\"direction is right top\")\n",
    "        else:\n",
    "            print(\"left down\")\n",
    "    else:\n",
    "        if(c_y >=0 & c_x <= 0):\n",
    "            print(\"top left\")\n",
    "        elif(c_y <=0 & c_x >= 0):\n",
    "            print(\"right_down\")\n",
    "        \n",
    "#trackedFrames = numpy.zeros((720,1280))\n",
    "\n",
    "\n",
    "\n",
    "def process_frame(frame):\n",
    "    # step 1 RGB to gray\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = gray\n",
    "    # step 2: filter video\n",
    "    blur = cv2.GaussianBlur(frame, (15,15), 0) \n",
    "    # find delta \n",
    "    image_diff = frame - blur\n",
    "    # find binary frames by thresholding\n",
    "    retval, thresh = cv2.threshold(image_diff, 10, 255, cv2.THRESH_BINARY)\n",
    "    frame = thresh\n",
    "    big_data.append(frame)\n",
    "    \n",
    "    centroids.append(centroid)\n",
    "     # calculate moments of binary image\n",
    "    M = cv2.moments(thresh)\n",
    " \n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    centroid = (cX, cY)\n",
    "   \n",
    "    \n",
    "   \n",
    "    return frame\n",
    "    \n",
    "    \n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    frame = process_frame(frame)\n",
    "    # should be called once the card is detected and the hand is moving back\n",
    "    track_frame(100)\n",
    "    # Save the video\n",
    "    out.write(frame)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "detections = [[0,1],[3,4],[7,8],[1,0],[5,6],[-2,-6]]\n",
    "# create a Kmeans object\n",
    "kmeans = MiniBatchKMeans(n_clusters=2,\n",
    "                          random_state=0,\n",
    "                          batch_size=200).fit(detections)\n",
    "\n",
    "\n",
    "centorids = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    " # appending all the centroids for later tracking purpose\n",
    "\n",
    " #MJPG-encoded AVI as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30409357 -1.66081871]\n",
      " [ 5.          6.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import math\n",
    "detections = [[0,1],[3,4],[7,8],[1,0],[5,6],[-2,-6]]\n",
    "num_players = 2\n",
    "# create a Kmeans object\n",
    "kmeans = MiniBatchKMeans(n_clusters = num_players,\n",
    "                          random_state=0,\n",
    "                          batch_size=200).fit(detections)\n",
    "\n",
    "centorids = kmeans.cluster_centers_\n",
    "print(centorids)\n",
    "\n",
    "card = [6,2]\n",
    "\n",
    "def get_closestCentroid(card, centroids):\n",
    "    distances = []\n",
    "    for centroid in centroids:\n",
    "        eculideanDistance = np.sqrt(pow((card[0]-centroid[0]),2) + pow((card[1]-centroid[1]),2))\n",
    "        distances.append(eculideanDistance)\n",
    "    return distances.index(min(distances))\n",
    "get_closestCentroid(card, detections)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
